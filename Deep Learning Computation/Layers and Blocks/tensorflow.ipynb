{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled23.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNCh0CEmVq823ttHysTy4/O",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anubhavgupta1/Dive-Into-Deep-Learning/blob/main/Deep%20Learning%20Computation/Layers%20and%20Blocks/tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoJIK_HF-u6P"
      },
      "source": [
        "#  Deep Learning Computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQrUoFmNY8_U"
      },
      "source": [
        "!pip install d2l==0.16.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_JJzaDIZFms"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBGptnQt3x2t"
      },
      "source": [
        "X = tf.random.uniform((2, 20))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8qWyE8G2_dV"
      },
      "source": [
        "### A Custom Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvx36wV-29qj"
      },
      "source": [
        "net = tf.keras.models.Sequential([\r\n",
        "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\r\n",
        "    tf.keras.layers.Dense(10),\r\n",
        "])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rriKnh_I3Wvt",
        "outputId": "a3b66ce9-20f1-4ccd-9a41-b75d48d36bc0"
      },
      "source": [
        "print(net(X))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.02454413  0.05374416 -0.22445574  0.10537914 -0.01967596  0.05305097\n",
            "  -0.02177824  0.24214353  0.31233367  0.06279922]\n",
            " [-0.12228318  0.12440787 -0.04207617 -0.141327   -0.04125782  0.15450881\n",
            "   0.2045113   0.192507    0.15914743  0.03142395]], shape=(2, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAAHnkEU3kwc"
      },
      "source": [
        "### MLP Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QFHMoGg3n77"
      },
      "source": [
        "class MLP(tf.keras.Model):\r\n",
        "    # Declare a layer with model parameters. Here, we declare two fully\r\n",
        "    # connected layers\r\n",
        "    def __init__(self):\r\n",
        "        # Call the constructor of the `MLP` parent class `Block` to perform\r\n",
        "        # the necessary initialization. In this way, other function arguments\r\n",
        "        # can also be specified during class instantiation, such as the model\r\n",
        "        # parameters, `params` (to be described later)\r\n",
        "        super().__init__()\r\n",
        "        # Hidden layer\r\n",
        "        self.hidden = tf.keras.layers.Dense(units=256, activation=tf.nn.relu)\r\n",
        "        self.out = tf.keras.layers.Dense(units=10)  # Output layer\r\n",
        "\r\n",
        "    # Define the forward propagation of the model, that is, how to return the\r\n",
        "    # required model output based on the input `X`\r\n",
        "    def call(self, X):\r\n",
        "        return self.out(self.hidden((X)))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6Gc-uwh3j2S",
        "outputId": "a5ed32ab-578b-4cfe-99e7-cdf65f193b69"
      },
      "source": [
        "net = MLP()\r\n",
        "print(net(X))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.12711485  0.16342229 -0.48333412  0.089953   -0.12214594  0.24096318\n",
            "   0.18865812  0.1727748  -0.07359472 -0.02697731]\n",
            " [-0.09546676  0.08119087 -0.3592066   0.10021627  0.0293078   0.00357199\n",
            "   0.00810516  0.37822014 -0.0345638   0.07874873]], shape=(2, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2ji4r0K4NHa"
      },
      "source": [
        "### The Sequential Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRhUsmVg4OVF"
      },
      "source": [
        "class MySequential(tf.keras.Model):\r\n",
        "    def __init__(self, *args):\r\n",
        "        super().__init__()\r\n",
        "        self.modules = []\r\n",
        "        for block in args:\r\n",
        "            # Here, `block` is an instance of a `tf.keras.layers.Layer`\r\n",
        "            # subclass\r\n",
        "            self.modules.append(block)\r\n",
        "\r\n",
        "    def call(self, X):\r\n",
        "        for module in self.modules:\r\n",
        "            X = module(X)\r\n",
        "        return X"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18yGeQCL4c3I"
      },
      "source": [
        "net = MySequential(\r\n",
        "    tf.keras.layers.Dense(units=256, activation=tf.nn.relu),\r\n",
        "    tf.keras.layers.Dense(10))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Td_b__g5bAY",
        "outputId": "09a2b74c-ae8f-40ae-cfa5-911e426dc45e"
      },
      "source": [
        "print(net(X))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.00583003  0.01177476  0.12718418 -0.5266906  -0.01847959 -0.20649724\n",
            "  -0.06827422  0.209494   -0.21486029  0.41507924]\n",
            " [ 0.22579806 -0.30515245  0.2524678  -0.35757127  0.30900776  0.01641573\n",
            "   0.26814288  0.12637533 -0.3970175   0.4101131 ]], shape=(2, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut0e0gbe7oDj"
      },
      "source": [
        "### Ensemble Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SypIkg7S7qd2"
      },
      "source": [
        "class FixedHiddenMLP(tf.keras.Model):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "        self.flatten = tf.keras.layers.Flatten()\r\n",
        "        # Random weight parameters created with `tf.constant` are not updated\r\n",
        "        # during training (i.e., constant parameters)\r\n",
        "        self.rand_weight = tf.constant(tf.random.uniform((20, 20)))\r\n",
        "        self.dense = tf.keras.layers.Dense(20, activation=tf.nn.relu)\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        X = self.flatten(inputs)\r\n",
        "        # Use the created constant parameters, as well as the `relu` and\r\n",
        "        # `matmul` functions\r\n",
        "        X = tf.nn.relu(tf.matmul(X, self.rand_weight) + 1)\r\n",
        "        # Reuse the fully-connected layer. This is equivalent to sharing\r\n",
        "        # parameters with two fully-connected layers\r\n",
        "        X = self.dense(X)\r\n",
        "        # Control flow\r\n",
        "        while tf.reduce_sum(tf.math.abs(X)) > 1:\r\n",
        "            X /= 2\r\n",
        "        return tf.reduce_sum(X)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfWnyP8h71cz",
        "outputId": "3150099e-5888-449d-c008-3d83f41df42a"
      },
      "source": [
        "net = FixedHiddenMLP()\r\n",
        "print(net(X))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.5202366, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZuwu4UK8LtH"
      },
      "source": [
        "class NestMLP(tf.keras.Model):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "        self.net = tf.keras.Sequential()\r\n",
        "        self.net.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\r\n",
        "        self.net.add(tf.keras.layers.Dense(32, activation=tf.nn.relu))\r\n",
        "        self.dense = tf.keras.layers.Dense(16, activation=tf.nn.relu)\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        return self.dense(self.net(inputs))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfjfMhdI8ScL",
        "outputId": "c5b773d5-cd15-4f46-e4e7-67f8ed9cfd48"
      },
      "source": [
        "net = NestMLP()\r\n",
        "print(net(X))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.09285448 0.49414733 0.         0.0551398  0.         0.\n",
            "  0.         0.         0.29116362 0.         0.         0.\n",
            "  0.6010559  0.33207092 0.19420975 0.09575619]\n",
            " [0.0252568  0.68659973 0.         0.         0.         0.\n",
            "  0.         0.         0.40465826 0.15191303 0.21433485 0.\n",
            "  0.3473198  0.02466469 0.1318965  0.27913833]], shape=(2, 16), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GeY0GOu8Oc0"
      },
      "source": [
        "chimera = tf.keras.Sequential()\r\n",
        "chimera.add(NestMLP())\r\n",
        "chimera.add(tf.keras.layers.Dense(20))\r\n",
        "chimera.add(FixedHiddenMLP())"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B4QYWv089PT",
        "outputId": "dcdb1eb2-a947-4d0b-d1ed-52264d27f6b3"
      },
      "source": [
        "print(chimera(X))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.7573608, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}