{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled23.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN0ImwdFMps8RxeXB0EZ538",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anubhavgupta1/Dive-Into-Deep-Learning/blob/main/Deep%20Learning%20Computation/Layers%20and%20Blocks/pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoJIK_HF-u6P"
      },
      "source": [
        "#  Deep Learning Computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQrUoFmNY8_U"
      },
      "source": [
        "!pip install d2l==0.16.1\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_JJzaDIZFms"
      },
      "source": [
        "import torch\r\n",
        "from torch import nn\r\n",
        "from torch.nn import functional as F"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBGptnQt3x2t"
      },
      "source": [
        "X = torch.rand(2, 20)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8qWyE8G2_dV"
      },
      "source": [
        "### A Custom Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvx36wV-29qj"
      },
      "source": [
        "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlsgcARB3Ydw",
        "outputId": "d92b2f6d-62e7-4122-9735-8127c1b61241"
      },
      "source": [
        "print(net)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=20, out_features=256, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rriKnh_I3Wvt",
        "outputId": "05bd20ea-4688-47a3-832a-b9e158ac984e"
      },
      "source": [
        "print(net(X))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.1362, -0.1454, -0.2778,  0.0576,  0.0218,  0.0943,  0.0904, -0.2205,\n",
            "          0.0724,  0.1856],\n",
            "        [ 0.1261, -0.1266, -0.1874,  0.0770,  0.0214,  0.1256,  0.2203, -0.0679,\n",
            "          0.1863,  0.0685]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAAHnkEU3kwc"
      },
      "source": [
        "### MLP Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QFHMoGg3n77"
      },
      "source": [
        "class MLP(nn.Module):\r\n",
        "    # Declare a layer with model parameters. Here, we declare two fully\r\n",
        "    # connected layers\r\n",
        "    def __init__(self):\r\n",
        "        # Call the constructor of the `MLP` parent class `Block` to perform\r\n",
        "        # the necessary initialization. In this way, other function arguments\r\n",
        "        # can also be specified during class instantiation, such as the model\r\n",
        "        # parameters, `params` (to be described later)\r\n",
        "        super().__init__()\r\n",
        "        self.hidden = nn.Linear(20, 256)  # Hidden layer\r\n",
        "        self.out = nn.Linear(256, 10)  # Output layer\r\n",
        "\r\n",
        "    # Define the forward propagation of the model, that is, how to return the\r\n",
        "    # required model output based on the input `X`\r\n",
        "    def forward(self, X):\r\n",
        "        # Note here we use the funtional version of ReLU defined in the\r\n",
        "        # nn.functional module.\r\n",
        "        return self.out(F.relu(self.hidden(X)))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6Gc-uwh3j2S",
        "outputId": "ff419d1c-8775-41e6-f168-fc2e14bb6c77"
      },
      "source": [
        "net = MLP()\r\n",
        "print(net)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP(\n",
            "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
            "  (out): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRysRhT939uh",
        "outputId": "15a15d58-c829-4d6a-ea9a-982165026740"
      },
      "source": [
        "print(net(X))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.3355, -0.1387, -0.0228, -0.2143, -0.0566, -0.2244, -0.1876, -0.0995,\n",
            "          0.2165,  0.2100],\n",
            "        [-0.3842, -0.1846,  0.0411, -0.3238, -0.1191, -0.1736, -0.0848, -0.1702,\n",
            "          0.3924,  0.2264]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2ji4r0K4NHa"
      },
      "source": [
        "### The Sequential Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRhUsmVg4OVF"
      },
      "source": [
        "class MySequential(nn.Module):\r\n",
        "    def __init__(self, *args):\r\n",
        "        super().__init__()\r\n",
        "        for block in args:\r\n",
        "            # Here, `block` is an instance of a `Module` subclass. We save it\r\n",
        "            # in the member variable `_modules` of the `Module` class, and its\r\n",
        "            # type is OrderedDict\r\n",
        "            self._modules[block] = block\r\n",
        "\r\n",
        "    def forward(self, X):\r\n",
        "        # OrderedDict guarantees that members will be traversed in the order\r\n",
        "        # they were added\r\n",
        "        for block in self._modules.values():\r\n",
        "            X = block(X)\r\n",
        "        return X"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18yGeQCL4c3I",
        "outputId": "732a8a67-dff5-43f2-bfb5-d0439eb7a829"
      },
      "source": [
        "net = MySequential()\r\n",
        "print(net)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MySequential()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe2q3j2F4f3l"
      },
      "source": [
        "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Td_b__g5bAY",
        "outputId": "4de6d1dd-300b-4e21-82cc-4a44112bd0d9"
      },
      "source": [
        "print(net(X))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0815, -0.0451,  0.0673,  0.0729,  0.0160,  0.1364,  0.0418,  0.1265,\n",
            "          0.0098,  0.1743],\n",
            "        [ 0.1499, -0.1856, -0.1090,  0.1220,  0.1083,  0.1272,  0.1133,  0.1505,\n",
            "         -0.0024,  0.1488]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut0e0gbe7oDj"
      },
      "source": [
        "### Ensemble Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SypIkg7S7qd2"
      },
      "source": [
        "class FixedHiddenMLP(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "        # Random weight parameters that will not compute gradients and\r\n",
        "        # therefore keep constant during training\r\n",
        "        self.rand_weight = torch.rand((20, 20), requires_grad=False)\r\n",
        "        self.linear = nn.Linear(20, 20)\r\n",
        "\r\n",
        "    def forward(self, X):\r\n",
        "        X = self.linear(X)\r\n",
        "        # Use the created constant parameters, as well as the `relu` and `mm`\r\n",
        "        # functions\r\n",
        "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\r\n",
        "        # Reuse the fully-connected layer. This is equivalent to sharing\r\n",
        "        # parameters with two fully-connected layers\r\n",
        "        X = self.linear(X)\r\n",
        "        # Control flow\r\n",
        "        while X.abs().sum() > 1:\r\n",
        "            X /= 2\r\n",
        "        return X.sum()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfWnyP8h71cz",
        "outputId": "46a6a0ba-4ed4-49ac-da58-beeebeeb2c5e"
      },
      "source": [
        "net = FixedHiddenMLP()\r\n",
        "print(net)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FixedHiddenMLP(\n",
            "  (linear): Linear(in_features=20, out_features=20, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7tEdTgk75r_",
        "outputId": "7312111f-5047-4471-ed39-442f02e9ff44"
      },
      "source": [
        "print(net(X))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.3358, grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZuwu4UK8LtH"
      },
      "source": [
        "class NestMLP(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "        self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(),\r\n",
        "                                 nn.Linear(64, 32), nn.ReLU())\r\n",
        "        self.linear = nn.Linear(32, 16)\r\n",
        "\r\n",
        "    def forward(self, X):\r\n",
        "        return self.linear(self.net(X))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfjfMhdI8ScL",
        "outputId": "58b699cb-537d-4142-bb03-7d5ddf21429d"
      },
      "source": [
        "net = NestMLP()\r\n",
        "print(net)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NestMLP(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=20, out_features=64, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (linear): Linear(in_features=32, out_features=16, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiHaEI6k8foA",
        "outputId": "322baa72-2dda-4511-ccb5-345457fb2992"
      },
      "source": [
        "print(net(X))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0430, -0.1136,  0.0344,  0.0052,  0.0080,  0.0799, -0.1661,  0.0553,\n",
            "          0.1131, -0.1121, -0.0420, -0.1781,  0.0803, -0.0538,  0.0892,  0.0685],\n",
            "        [-0.0614, -0.0389,  0.0563, -0.0055, -0.0073,  0.1124, -0.1901,  0.0569,\n",
            "          0.1194, -0.0985, -0.0510, -0.1804,  0.0882, -0.0835,  0.0423,  0.1408]],\n",
            "       grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GeY0GOu8Oc0",
        "outputId": "aec41356-9a9f-4da3-f812-9a78544d999f"
      },
      "source": [
        "chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixedHiddenMLP())\r\n",
        "print(chimera)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): NestMLP(\n",
            "    (net): Sequential(\n",
            "      (0): Linear(in_features=20, out_features=64, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=64, out_features=32, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (linear): Linear(in_features=32, out_features=16, bias=True)\n",
            "  )\n",
            "  (1): Linear(in_features=16, out_features=20, bias=True)\n",
            "  (2): FixedHiddenMLP(\n",
            "    (linear): Linear(in_features=20, out_features=20, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B4QYWv089PT",
        "outputId": "3280bfc2-643c-4d5a-adde-4279497d0dc2"
      },
      "source": [
        "print(chimera(X))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0617, grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}